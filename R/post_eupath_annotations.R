#' Create a series of POST requests which download all the annotation data for a species.
#'
#' The only way I have figured out how to download mass data from the eupathdb
#' is to ask for a raw dump of all available data using the GenesByGeneType
#' WADL.  Therefore, this function iterates over the various sequence types that
#' I have noticed at the eupathdb and does that for each type.
#'
#' @param entry Eupathdb annotation entry.
#' @param build_dir Location to dump the resulting data.
#' @param overwrite Overwrite existing data if it exists?
post_eupath_annotations <- function(entry = NULL, overwrite = FALSE, build_dir = "EuPathDB") {
    if (is.null(entry)) {
        stop("  Need an entry from the eupathdb.")
    }

    ## Check for output rda directory and create it if necessary
    rdadir <- file.path(build_dir, "rda")
    if (!file.exists(build_dir)) {
        created <- dir.create(build_dir, recursive = TRUE)
    }

    ## Look for an existing savefile and load if we are not overwriting existing data.
    savefile <- file.path(build_dir, glue::glue("{entry[['Genome']]}_annotations.rda"))
    if (file.exists(savefile)) {
        if (isTRUE(overwrite)) {
            removed <- file.remove(savefile)
        } else {
            message("  Delete the file ", savefile, " to regenerate.")
            result <- new.env()
            load(savefile, envir = result)
            result <- result[["result"]]
            return(result)
        }
    }

    ## query body as a structured list
    ## This list was generated by going to:
    ## view-source:http://tritrypdb.org/webservices/GeneQuestions/GenesByMolecularWeight.wadl
    ## scrolling down to the 'o-fields' section, and writing down the most likely
    ## useful column names.
    ## I later came through and wrote a function function to automagically populate this list.
    species <- entry[["TaxonUnmodified"]]
    webservice <- tolower(entry[["DataProvider"]])
    ## Use a query to find what annotation types are available: protein coding vs. rRNA vs. etc...
    types <- get_eupath_gene_types(webservice = webservice)
    result <- data.frame()

    ## Excepting schistodb, all the services are .orgs which is a .net.
    tld <- "org"
    if (webservice == "schistodb") {
        tld <- "net"
    }
    ## Finalize the URL to query using the webservice, tld, etc.
    service_directory <- prefix_map(webservice)
    ## download_json <- glue::glue("{build_dir}/{species_filename}.json")
    base_url <- glue::glue("https://{webservice}.{tld}/{service_directory}/service/record-types/transcript/searches/GenesByTaxon/reports/standard")
    wanted_columns <- get_semantic_columns(webservice = webservice)
    split_columns <- split(wanted_columns, ceiling(seq_along(wanted_columns) / 20))
    ##wanted_columns <- c("primary_key", "wdk_weight", "has_missing_transcripts", "gene_name",
    ##                    "gene_source_id", "gene_previous_ids", "gene_product", "transcript_product",
    ##                    "gene_exon_count", "exon_count", "gene_transcript_count",
    ##                    "three_prime_utr_length", "five_prime_utr_length", "strand", "gene_type",
    ##                    "is_pseudo", "transcript_length", "gene_entrez_id", "uniprot_id",
    ##                    "chromosome", "gene_location_text", "location_text", "sequence_id",
    ##                    "organism", "gene_ortholog_number", "gene_orthomcl_name",
    ##                    "gene_paralog_number", "gene_hts_noncoding_snps",
    ##                    "gene_hts_nonsyn_syn_ratio", "gene_hts_nonsynonymous_snps",
    ##                    "gene_hts_stop_codon_snps", "gene_hts_synonymous_snps",
    ##                    "gene_total_hts_snps", "cds", "transcript_sequence", "protein_sequence",
    ##                    "protein_length", "cds_length", "molecular_weight", "isoelectric_point",
    ##                    "interpro_id", "interpro_description", "pfam_id", "pfam_description",
    ##                    "pirsf_id", "pirsf_description", "prositeprofiles_id",
    ##                    "prositeprofiles_description", "smart_id", "smart_description",
    ##                    "superfamily_id", "superfamily_description", "tigrfam_id",
    ##                    "tigrfam_description", "new_product_name", "tm_count", "signalp_peptide",
    ##                    "signalp_scores", "predicted_go_id_component", "predicted_go_component",
    ##                    "predicted_go_id_function", "predicted_go_function",
    ##                    "predicted_go_id_process", "predicted_go_process",
    ##                    "annotated_go_id_component", "annotated_go_component",
    ##                    "annotated_go_id_function", "annotated_go_function",
    ##                    "annotated_go_id_process", "annotated_go_process", "ec_numbers",
    ##                    "ec_numbers_derived")
    all_records <- data.frame()
    for (g in 1:length(split_columns)) {
      group <- split_columns[[g]]
      query_body <- list(
        "searchConfig" = list(
          "parameters" = list("organism" = jsonlite::unbox(species)),
          "wdkWeight" = jsonlite::unbox(10)),
        "reportConfig" = list(
          "attributes" = group,
          "tables" = list()))
      post_json <- jsonlite::toJSON(query_body)
      result <- httr::POST(url = base_url, body = post_json,
                           httr::content_type("application/json"),
                           httr::timeout(1200))
      ## Test the result to see that we actually got data.
      if (result[["status_code"]] == "422") {
        warn(sprintf("API request failed for %s (code = 422): ", entry[["Taxon"]]))
        next
      } else if (result[["status_code"]] == "400") {
        ## likely due to bad formatConfig
        warn("API Request failed for ", entry[["TaxonUnmodified"]], ": (code = 400)")
        next
      } else if (result[["status_code"]] == "404") {
        warn("API Request failed for ", entry[["TaxonUnmodified"]], ": (code = 404)")
        next
      } else if (result[["status_code"]] != "200") {
        warn("API Request failed for ", entry[["TaxonUnmodified"]], ": (code = ",
             result[["status_code"]], ")")
        next
      } else if (length(result[["content"]]) < 100) {
        warn("Very small amount of content returned for :", entry[["Taxon"]])
        next
      }
      cont <- httr::content(result, encoding = "UTF-8", as = "text")
      ## result <- try(jsonlite::fromJSON(cont, flatten = TRUE))
      result <- try(jsonlite::fromJSON(cont, flatten = TRUE))

      ## Every record contains and id, some fields, and tables.
      records <- result[["records"]]
      colnames(records) <- gsub(pattern = "^attributes\\.", replacement = "", x = colnames(records))
      colnames(records) <- gsub(pattern = "\\.", replacement = "_", x = colnames(records))
      records <- expand_list_columns(records)
      ## Drop some annoying columns
      records[["recordClassName"]] <- NULL

      if (g == 1) {
        all_records <- records
        ## "displayName" "overview" "gene_location_text" "gene_name" "organism" "
        ## "gene_transcript_count" "lc_project_id" "gene_exon_count" "chromosome"
        ## "primary_key" "gene_type" "project_id" "is_deprecated" "gene_source_id" "transcript_link"
        ## "sequence_id" "is_pseudo" "snpoverview" "gene_product" "source_id" "gene_ortholog_number"
      } else {
        ## shared_columns <- colnames(records) %in% colnames(all_records)
        ## records[, shared_columns] <- NULL
        records[["gene_source_id"]] <- NULL
        records[["source_id"]] <- NULL
        records[["project_id"]] <- NULL
        all_records <- merge(all_records, records, by = "displayName")
      }
      message("Snoozing to try to keep the webserver from being sad.")
      snooze <- Sys.sleep(3)
    }  ## End of my nasty hack to get around some webservices crashing
    ##    when I ask for all the columns.

    records <- all_records
    ## Use a heuristic to figure out numeric columns and set them accordingly.
    cnames <- colnames(records)
    for (i in 1:length(cnames)) {
      cname <- cnames[i]
      column <- records[[cname]]
      idx <- !is.na(column)
      column <- column[idx]
      res <- suppressWarnings(!is.na(as.numeric(as.character(column))))
      if (sum(res) == length(column)) {
        message("Setting ", cname, " to numeric.")
        records[[cname]] <- as.numeric(records[[cname]])
      }
    }

    ## Change entries which say 'N/A' to the actual NA value
    na_idx <- records == "N/A" | records == "NA"
    false_idx <- is.na(records)
    na_idx[false_idx] <- FALSE
    records[na_idx] <- NA

    ## Hopefully the data is consistent now, so let us change the column names
    ## and send the NAs to a contextually sensible value that sqlite will not yell about
    ## e.g. if a column is numeric, set it to 0; if a column is a character, set it to ""
    colnames(records) <- paste0("annot_", colnames(records))
    for (col_num in 1:length(colnames(records))) {
        cname <- colnames(records)[col_num]
        na_idx <- is.na(records[[col_num]])
        if (is.character(records[[col_num]])) {
            records[na_idx, col_num] <- ""
        } else {
            records[na_idx, col_num] <- 0
        }
        ## Cast factor columns explicitly as factors
        test_col <- as.factor(records[[col_num]])
        test_levels <- length(levels(test_col))
        if (test_levels < 50) {
            message("Setting ", cname, " to a factor.")
            records[[col_num]] <- as.factor(records[[col_num]])
        }
    }

    ## orgdbs seem to like uppercase column names
    colnames(records) <- toupper(colnames(records))

    ## Drop a few extra dumb columns
    drop_columns <- c("ANNOT_ORGANISM", "ANNOT_ORGANISM_FULL", "ANNOT_ORGANISM_TEXT",
                      "ANNOT_RECORDCLASSNAME", "ANNOT_PROJECT_ID", "ANNOT_PROJECT",
                      "ANNOT_LC_PROJECT_ID", "ANNOT_GENE_SOURCE_ID", "ANNOT_SOURCE_ID")
    for (d in drop_columns) {
      if (!is.null(records[[d]])) {
        records[[d]] <- NULL
      }
    }

    ## Do an extra pass for weird NAs
    for (cname in colnames(records)) {
      na_idx <- grepl("^#N/A", records[[cname]])
      records[na_idx, cname] <- ""
    }

    ## I would like to get rid of any html tags

    ## Get rid of duplicated entries
    dup_idx <- duplicated(records)
    if (sum(dup_idx) > 0) {
        message("  Dropped ", sum(dup_idx), " duplicated entries.")
    }
    records <- records[!dup_idx, ]

    message("  Saving ", savefile, " with ", nrow(records), " rows.")
    save(records, file = savefile)
    return(records)
}
